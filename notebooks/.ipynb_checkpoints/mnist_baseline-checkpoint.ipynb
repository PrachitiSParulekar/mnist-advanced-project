{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8c0efb-8de2-45b5-9e0d-690713748fbc",
   "metadata": {},
   "source": [
    "Mnist Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed49db-a3ba-4538-8cb4-a564e6b926b8",
   "metadata": {},
   "source": [
    "Step 1 : load Mnist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2b5145-8654-4bfa-8d89-7a1f140e2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00febd19-0bed-4c83-bb1d-da32567bc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train = True , download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507650e-abdf-4c93-9086-c466feec1359",
   "metadata": {},
   "source": [
    "transform = transforms.Compose([...])\n",
    "This line creates a transformation pipeline for the MNIST images, including:\n",
    "\n",
    "transforms.ToTensor(): Converts each MNIST image from a PIL image (or numpy array) to a PyTorch tensor, which is required for model training.\n",
    "\n",
    "transforms.Normalize((0.1307,), (0.3081,)): Normalizes the pixel values using the dataset's mean (0.1307) and standard deviation (0.3081). Normalization helps training converge faster and improves performance by ensuring all pixel values are on a similar scale.\n",
    "\n",
    "train_dataset = datasets.MNIST(...)\n",
    "This loads the MNIST training dataset from ./data directory. It:\n",
    "\n",
    "Downloads the data if it doesn’t exist yet.\n",
    "\n",
    "Applies the transformations defined above to each image, prepping the data for use in PyTorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3e2ab9-4cc4-43b8-bf3e-8f4f1a53d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training samples: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d89734-eda0-49dd-9e2a-05e60025d29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(12, 3))\n",
    "for i in range(6):\n",
    "    image, label = train_dataset[i]\n",
    "    image = image.squeeze()  # remove channel dimension for plotting\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {label}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aefce2-b113-4e19-9e49-f802c4f48c88",
   "metadata": {},
   "source": [
    "Set Up DataLoader for Training\n",
    "PyTorch’s DataLoader helps you:\n",
    "*Batch the data for efficient training\n",
    "*Shuffle data for randomness in each epoch\n",
    "*Load data as needed, saving memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6d29dd-1a8e-471d-935d-89e3f2a61457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e75d1a-410a-4777-a452-2f8da35a6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfa504-06fd-492e-988d-3e2c10328b2b",
   "metadata": {},
   "source": [
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06a82b-004a-4970-9a6d-b6fad08f6b32",
   "metadata": {},
   "source": [
    "Define the Classic CNN Model\n",
    "Let’s start with a simple LeNet-style architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e26b787-3215-445b-b2bc-385d89a5517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57caec7-db70-420e-bb1c-c56b6af0b04f",
   "metadata": {},
   "source": [
    "This model takes 28x28 MNIST images, extracts features with convolutional and pooling layers, flattens the features, and classifies the digits 0–9 with the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a490eb0f-be7d-4bc0-9358-24aa338e639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()     # For multiclass classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdd829-b65e-4a3c-b5f6-5b4a93a866b9",
   "metadata": {},
   "source": [
    "1. Loss Function:\n",
    "\n",
    "python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "Purpose: Measures how well your model's predictions match the true labels.\n",
    "\n",
    "Why CrossEntropy? For multiclass classification, like digit recognition (0–9), cross-entropy quantifies the difference between your model's predicted probabilities and the actual digit class. It gives a higher penalty for confident but wrong guesses, encouraging better learning.\n",
    "\n",
    "2. Optimizer:\n",
    "\n",
    "python\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "Purpose: Updates the model's weights after each batch of training data to reduce the loss.\n",
    "\n",
    "Why Adam? Adam is an advanced optimizer that adapts learning rates for different parameters, often leading to faster and more stable training compared to plain SGD.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "model.parameters(): Tells Adam which model weights to update.\n",
    "\n",
    "lr=0.001: Starting learning rate (how much weights change in response to calculated error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48477984-750a-4243-b415-6d5ce847ffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.1403\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 1  # We'll start with 1 epoch for demonstration\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()                   # reset gradients\n",
    "        outputs = model(images)                 # forward pass\n",
    "        loss = criterion(outputs, labels)       # compute loss\n",
    "        loss.backward()                         # backward pass\n",
    "        optimizer.step()                        # update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea105e1-6b32-4ff4-b869-783a0201d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.19%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0049133-bed7-4201-b35c-8e249283ae5a",
   "metadata": {},
   "source": [
    "Train for more epochs to see if accuracy improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33434b2b-564f-4925-8eb6-13ca75f8a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0431\n",
      "Epoch 2/10, Loss: 0.0299\n",
      "Epoch 3/10, Loss: 0.0207\n",
      "Epoch 4/10, Loss: 0.0157\n",
      "Epoch 5/10, Loss: 0.0130\n",
      "Epoch 6/10, Loss: 0.0114\n",
      "Epoch 7/10, Loss: 0.0080\n",
      "Epoch 8/10, Loss: 0.0084\n",
      "Epoch 9/10, Loss: 0.0065\n",
      "Epoch 10/10, Loss: 0.0073\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "668e0263-409e-4454-a6c6-84b1aef2b98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.94%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e0b6ed-c884-4d62-bc32-bfcafed27edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Store misclassified images, their predicted and true labels\n",
    "misclassified = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for img, true, pred in zip(images, labels, predicted):\n",
    "            if true != pred:\n",
    "                misclassified.append((img.cpu(), true.cpu(), pred.cpu()))\n",
    "            if len(misclassified) >= 6:\n",
    "                break\n",
    "        if len(misclassified) >= 6:\n",
    "            break\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 3))\n",
    "for i, (img, true, pred) in enumerate(misclassified[:6]):\n",
    "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f\"T:{true} P:{pred}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f85f6560-8f47-4e26-b48b-719c83f6ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)  # Add dropout with probability 0.25\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 256)  # Increase neuron count (was 128)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.dropout(x)              # Apply dropout before fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd1000-c314-4d0e-ab0f-017e6a8343c8",
   "metadata": {},
   "source": [
    "1. Dropout Layer (nn.Dropout(0.25)):\n",
    "\n",
    "What: Randomly sets 25% of its input units to zero during each training step.\n",
    "\n",
    "Why: Prevents the network from becoming too reliant (“overfitting”) on particular features, encouraging it to learn more general patterns that work well on unseen data.\n",
    "\n",
    "2. Increased Neurons in fc1 Layer (nn.Linear(64*7*7, 256)):\n",
    "\n",
    "What: Expands the fully connected layer from 128 neurons to 256.\n",
    "\n",
    "Why: More neurons give the network greater capacity to learn complex patterns and relationships in the data.\n",
    "\n",
    "Effect: Sometimes leads to better accuracy, especially for difficult tasks; but can also increase risk of overfitting if unchecked (which is why dropout helps here).\n",
    "\n",
    "How it works in forward pass:\n",
    "\n",
    "Images move through feature extraction layers (conv, pool).\n",
    "\n",
    "The resulting feature tensor is flattened.\n",
    "\n",
    "Dropout randomly zeroes out parts of the feature tensor.\n",
    "\n",
    "The dropped-out tensor goes through a larger fully connected layer (256 neurons), activated by ReLU.\n",
    "\n",
    "Final layer produces probability logits for each digit class.\n",
    "\n",
    "Summary:\n",
    "\n",
    "Dropout = better generalization (less overfit).\n",
    "\n",
    "More neurons = higher learning capacity.\n",
    "\n",
    "Used together, they should help your model stay accurate on both training and test data—even if you make it deeper or more complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c13cf342-a496-4e5d-a556-b5d037171505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd462700-5935-4ad4-9732-a27848288721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.1333\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1fd753e-db68-46c1-a606-82a831e7ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.60%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8336b86-928c-43d9-936d-1df51310cb52",
   "metadata": {},
   "source": [
    "we can see after experiment with architecture/tuning , test accuracy has increase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "299f87ab-e79c-4cc4-b69f-b8598fabbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0468\n",
      "Epoch 2/5, Loss: 0.0327\n",
      "Epoch 3/5, Loss: 0.0263\n",
      "Epoch 4/5, Loss: 0.0229\n",
      "Epoch 5/5, Loss: 0.0173\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87dd3666-eea1-4255-82be-35e109db9521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.21%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f1b96-4274-48d9-a32e-cae5d5ff11b1",
   "metadata": {},
   "source": [
    "Achieved more accuracy on this architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4482104c-ad60-4706-92b1-14af8e974d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  # <- new layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(128*3*3, 256)  # Adjust for new conv layer\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))    # <- new layer used\n",
    "        x = x.view(-1, 128*3*3)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f06a3ede-33b1-491e-983f-652d0cbbda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b07b40-af2a-4087-b9c8-ef7a9aec2d2f",
   "metadata": {},
   "source": [
    "Add Another Convolutional Layer\n",
    "Try adding one more convolutional layer (e.g., conv3) to your SimpleCNN:\n",
    "And in the forward() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2110164-eb7f-4279-afaa-39fc3b59f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.1427\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d297dfb5-aead-4aae-af59-e8b79cc2fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.86%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457a042-873a-473b-b589-9fb30fdae123",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599a84c-27d5-4fe8-95b2-38a794f37a38",
   "metadata": {},
   "source": [
    "Update the transform for your training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4dc4afc5-8e40-4a98-b24d-155df0b28d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Randomly rotate images by up to ±10 degrees\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d255b-f68b-442f-989c-9b7588344bfb",
   "metadata": {},
   "source": [
    "Re-instantiate your training dataset with the new transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46040a6c-4787-475e-81ba-cc6f949e4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3261b19-9c4f-4670-bc54-98b0c99a4c36",
   "metadata": {},
   "source": [
    "Retrain your model and compare test accuracy and misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c7faa5f-f75f-4f6f-bb12-f8b811ef0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.1647\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1  # You can increase or decrease as needed\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN().to(device)  # Re-instantiate after any changes!\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cc1b6df-f857-4ea1-b359-a1c5ebc028f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.90%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradients for evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef1554af-fdbc-4735-82ed-c10d12c3a1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store misclassified images, their predicted and true labels\n",
    "misclassified = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for img, true, pred in zip(images, labels, predicted):\n",
    "            if true != pred:\n",
    "                misclassified.append((img.cpu(), true.cpu(), pred.cpu()))\n",
    "            if len(misclassified) >= 6:\n",
    "                break\n",
    "        if len(misclassified) >= 6:\n",
    "            break\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 3))\n",
    "for i, (img, true, pred) in enumerate(misclassified[:6]):\n",
    "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f\"T:{true} P:{pred}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba7116-49ad-4c80-b0d7-4f22884048f6",
   "metadata": {},
   "source": [
    "Data augmentation simulates “real-world” scenarios for digit recognition, which encourages the network to learn more generalizable features and reduces overfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe5a5b4c-e6af-43a5-a202-e26774d09eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model parameters (recommended)\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174fa8a-8367-47e9-8b15-d1534b6c543f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnist-venv)",
   "language": "python",
   "name": "mnist-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
